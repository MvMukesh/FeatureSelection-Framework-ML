# Feature Selection Machine Learning
Answer of how to select variables in data set and build simpler, faster, more reliable and interpretable machine learning models

<hr>
<p align="center">
  <kbd><img src="https://user-images.githubusercontent.com/26667491/221211426-ad4fa8ec-e8cc-46c1-8c8f-74608f5f4289.png" height='300' width='1000'/> </kbd>
<p align="right">
  <!-- <img src="https://github.com/MvMukesh/Feature-Selection-ML/blob/main/images/working_on_it.gif" height='90' width='170'/> -->

  
1. `Feature Selection Methods`
  * Filter Methods
    * Variance 
    * Correlation
    * Univariate Selection
  * Wrapper Methods
    * Forward Feature Selection
    * Backword Feature Elemenation
    * Exaustive Search
  * Embedded / Hybrid Methods
    * LASSO
    * Tree Importance
  * Moving Forward

| Feature Selection Methods | Code + Blog Link| Video Link |
|------------------------------------|-----------------|------------|
| | | |
| | | |
| | | |
 
 2. Feature Selection -- `Basic Methods`
   
  * Removing 
    * Constant Features
    * Quasi-Constant Features
    * Duplicated Features

| Feature Selection -- Basic Methods | Code + Blog Link| Video Link |
|------------------------------------|-----------------|------------|
| | | |
| | | |
| | | |


3. Feature Selection -- `Correlation`

  * Removing Correlated Features
  * Basic Selection Methods + Correlation -> Pipeline

| Feature Selection -- Correlation | Code + Blog Link| Video Link |
|------------------------------------|-----------------|------------|
| | | |
| | | |
| | | |

## `Filter Methods`
4. `Univariate Statistical Methods`
  * Mutual Information
  * Chi-square distribution
  * Anova
  * Basic Selection Methods + Statistical Methods -> Pipeline

| Univariate Statistical Methods -- Filter Method | Code + Blog Link| Video Link |
|-------------------------------------------------|-----------------|------------|
| | | |
| | | |
| | | |
  
5. `Other Methods and Metrics`
  * Univariate ROC-AUC, MSE etc
  * Method used in a KDD competition - 2009
  
## `Wrapper Methods`
6. `Wrapper Methods`
  * Forward Feature Selection
  * Backward Feature Selection
  * Exhaustive Feature Selection
  
| Wrapper Methods -- Feature Selection| Code + Blog Link| Video Link |
|-------------------------------------|-----------------|------------|
| | | |
| | | |
| | | |
 
## `Embedded Methods`
7. `Linear Model Coefficients` 
  * Logistic Regression Coefficients
  * Linear Regression Coefficients
  * Effect of Regularization on Coefficients
  * Basic Selection Methods + Correlation + Embedded -> Pipeline

| Linear Model Coefficients| Code + Blog Link| Video Link |
|--------------------------|-----------------|------------|
| | | |
| | | |
| | | |
  
8. `Lasso`
  * Lasso
  * Basic Selection Methods + Correlation + Lasso -> Pipeline

| Lasso| Code + Blog Link| Video Link |
|------|-----------------|------------|
| | | |
| | | |
| | | |
  
9. `Tree Importance`
  * Random Forest derived Feature Importance
  * Tree importance + Recursive Feature Elimination
  * Basic Selection Methods + Correlation + Tree importance -> Pipeline 
  
| Tree Importance| Code + Blog Link| Video Link |
|----------------|-----------------|------------|
| | | |
| | | |
| | | |
 
## `Hybrid Methods`
10. `Hybrid Methods`
  * Feature Shuffling
  * Recursive Feature Elimination
  * Recursive Feature Addition
  
| Hybrid Methods| Code + Blog Link| Video Link |
|----------------|-----------------|------------|
| | | |
| | | |
| | | |  
  
  
  
